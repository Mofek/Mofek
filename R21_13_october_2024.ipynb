{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMWTzESRN0+hl471CE17HbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mofek/Mofek/blob/main/R21_13_october_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "vvgX_cK4Rv0B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t0OA--Lxvspy",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebea9e1-174b-4e2d-eb13-9e6d8f3bab36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.4/404.4 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting json-repair\n",
            "  Downloading json_repair-0.30.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading json_repair-0.30.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: json-repair\n",
            "Successfully installed json-repair-0.30.0\n",
            "Collecting py2neo\n",
            "  Downloading py2neo-2021.2.4-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from py2neo) (2024.8.30)\n",
            "Collecting interchange~=2021.0.4 (from py2neo)\n",
            "  Downloading interchange-2021.0.4-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting monotonic (from py2neo)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from py2neo) (24.1)\n",
            "Collecting pansi>=2020.7.3 (from py2neo)\n",
            "  Downloading pansi-2020.7.3-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.18.0)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from py2neo) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from py2neo) (2.2.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from interchange~=2021.0.4->py2neo) (2024.2)\n",
            "Downloading py2neo-2021.2.4-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n",
            "Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: monotonic, pansi, interchange, py2neo\n",
            "Successfully installed interchange-2021.0.4 monotonic-1.6 pansi-2020.7.3 py2neo-2021.2.4\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.10/dist-packages (5.25.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2024.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.134)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv\n",
        "!pip install json-repair\n",
        "!pip install --upgrade --quiet  langchain-openai langchain-community\n",
        "!pip install  py2neo\n",
        "!pip install PyPDF2\n",
        "!pip install neo4j\n",
        "!pip install --upgrade --quiet  langchain-openai langchain-community\n",
        "!pip install pandas\n",
        "!pip install langchain\n",
        "!pip install pydantic\n",
        "!pip install faiss-gpu\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import  RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "#from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "import pandas as pd\n",
        "from py2neo import Graph, Node, Relationship\n",
        "import PyPDF2\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "import yaml\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWRzuMOpvy23",
        "outputId": "79466de3-3cc0-4fe4-ebef-7bd42bb43310"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data section**"
      ],
      "metadata": {
        "id": "tLhV7YRsp_s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#if you want to load pdf file use this code\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "pdf_path = '/content/2023-Texas-Cancer-Registry-Annual-Report.pdf'  # Replace with your actual PDF path\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
        "documents1 = text_splitter.split_documents([Document(page_content=text)])\n",
        "print(documents1[:10])"
      ],
      "metadata": {
        "id": "QNm5_GhXZqOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc94d87-71a4-4293-ce5d-1307b5f3fb38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={}, page_content='2023 Texas Cancer Regist ry  \\n                         Annual Report\\n \\n \\nAs Required by  \\n       Texas Health and Safety Code,  \\n    Section 82.007  \\n \\n \\nSeptember  2023 \\n i \\n Table of Contents'), Document(metadata={}, page_content='Table of Contents  \\nExecutive Summary  ................................ ................................ ...............  2 \\nIntroduction  ................................ ................................ ...........................  3'), Document(metadata={}, page_content='1. Cancer in Tex as ................................ ................................ .................  5 \\nCancer Incidence  ................................ ................................ ................  5'), Document(metadata={}, page_content='Cancer Mortality  ................................ ................................ .................  6 \\nCancer Survival  ................................ ................................ ..................  7'), Document(metadata={}, page_content='Prevalence of Cancer  ................................ ................................ ...........  8 \\n2. Cance r in Children and Adolescents  ................................ ...................  9'), Document(metadata={}, page_content='3. Texas Cancer Registry Data Uses  ................................ ....................  11 \\nCancer Surveillance  ................................ ................................ ...........  11'), Document(metadata={}, page_content='Cancer Research  ................................ ................................ ...............  11 \\nEpidemiologic Studies  ................................ ................................ ........  11'), Document(metadata={}, page_content='Health Care Management  ................................ ................................ ... 13 \\nCommunity Efforts  ................................ ................................ ............  13'), Document(metadata={}, page_content='Cancer Cluster Investigations  ................................ ..............................  14 \\n4. Accessing Texas Cancer Data  ................................ ..........................  15'), Document(metadata={}, page_content='List of Acronyms  ................................ ................................ ..................  16 2 \\n Executive Summary  \\nThe Department of State Health Services (DSHS) is required to maintain the Texas')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#USE FOR CSV FILE\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Step 1: Load the CSV file\n",
        "csv_file_path = '/content/HumanOmniExpress-12-v1-0-K.csv'\n",
        "df = pd.read_csv(csv_file_path, sep=';',on_bad_lines='skip', engine='python')\n",
        "\n",
        "# Step 2: Concatenate the text data\n",
        "# Assuming the text you want to process is in a column named 'text'\n",
        "# Modify 'text' to the appropriate column name in your CSV\n",
        "column_name = df.columns[0]\n",
        "text_data = \" \".join(df[column_name].astype(str).tolist())\n",
        "\n",
        "# Create a Document object from the text data\n",
        "docs = [Document(page_content=text_data)]\n",
        "\n",
        "# Step 3: Split the text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(documents=docs)\n",
        "documents = documents[:100]\n",
        "# Check the result\n",
        "for i, doc in enumerate(documents[:10]):\n",
        "    print(f\"Chunk {i+1}: {doc.page_content}\\n\")\n",
        "documents.extend(documents1)\n",
        "print(documents[:1000])\n",
        "\n"
      ],
      "metadata": {
        "id": "N0ek9pwSnZLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you want to load TXT file use this code\n",
        "\n",
        "loader = TextLoader(file_path=\"/content/dummytext.txt\")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(documents=docs)\n",
        "print(documents[:10])"
      ],
      "metadata": {
        "id": "sjfgnbze_MIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_type = os.getenv(\"LLM_TYPE\", \"GPT_MODEL\")\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "VCfSgu8JHf0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_type = os.getenv(\"LLM_TYPE\", \"GPT_MODEL\")\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
        "\n",
        "#template = \"\"\"Please help me generate a knowledge graph from the following data and descriptions \"\"\"\n",
        "\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents1)\n"
      ],
      "metadata": {
        "id": "4kUYar_g_WwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_documents[0]"
      ],
      "metadata": {
        "id": "vwAY3tvV_dKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a38071-ff85-462d-ed2e-af6bc588c455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphDocument(nodes=[Node(id='American Lung Association', type='Organization', properties={}), Node(id='State Of Lung Cancer Report', type='Report', properties={}), Node(id='Lung Cancer', type='Disease', properties={}), Node(id='State', type='Location', properties={})], relationships=[Relationship(source=Node(id='American Lung Association', type='Organization', properties={}), target=Node(id='State Of Lung Cancer Report', type='Report', properties={}), type='PUBLISH', properties={}), Relationship(source=Node(id='State Of Lung Cancer Report', type='Report', properties={}), target=Node(id='Lung Cancer', type='Disease', properties={}), type='ANALYZE', properties={}), Relationship(source=Node(id='State Of Lung Cancer Report', type='Report', properties={}), target=Node(id='State', type='Location', properties={}), type='COMPARE', properties={})], source=Document(metadata={}, page_content='How does your state compare?\\ue913 SELECT LOCATION\\nThe American Lung Association\\'s \"State of Lung Cancer\" repor\\x00 explores how lung cancer varies by state. It does this by analyzing key lung'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")"
      ],
      "metadata": {
        "id": "wnEbaxvr_jsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Graph presentation***"
      ],
      "metadata": {
        "id": "Me-60CR1qHu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showGraph():\n",
        "    driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
        "                os.environ[\"NEO4J_PASSWORD\"]))\n",
        "    session = driver.session()\n",
        "    widget = GraphWidget(graph = session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
        "    widget.node_label_mapping = 'id'\n",
        "    return widget\n",
        "\n",
        "showGraph()"
      ],
      "metadata": {
        "id": "sCopbSZb_lod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Initialize the Neo4j driver\n",
        "driver = GraphDatabase.driver(\n",
        "    uri=os.environ[\"NEO4J_URI\"],\n",
        "    auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])\n",
        ")\n",
        "\n",
        "# Function to get all node labels\n",
        "def get_all_node_labels(driver):\n",
        "    with driver.session() as session:\n",
        "        result = session.run(\"\"\"\n",
        "            MATCH (n)\n",
        "            UNWIND labels(n) AS label\n",
        "            RETURN DISTINCT label\n",
        "        \"\"\")\n",
        "        node_labels = [record[\"label\"] for record in result]\n",
        "    return node_labels\n",
        "\n",
        "# Get all node labels\n",
        "node_labels = get_all_node_labels(driver)\n",
        "print(\"Node Labels:\", node_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHdhI2pZDXuc",
        "outputId": "0a6b58ef-0e88-414a-9e8c-877ca7eea75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node Labels: ['sample', 'Sex', 'county', 'Population', 'Superpopulation', 'Data_collections', 'state', 'Cancer_Type', 'Chromosome', 'SNP', 'Gene', 'Allele']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_string_property_keys(driver):\n",
        "    with driver.session() as session:\n",
        "        result = session.run(\"\"\"\n",
        "            MATCH (n)\n",
        "            UNWIND keys(n) AS key\n",
        "            WITH DISTINCT key\n",
        "            RETURN key\n",
        "        \"\"\")\n",
        "        property_keys = []\n",
        "        for record in result:\n",
        "            key = record[\"key\"]\n",
        "            # Check if the property values are strings\n",
        "            prop_result = session.run(f\"\"\"\n",
        "                MATCH (n)\n",
        "                WHERE n.`{key}` IS NOT NULL\n",
        "                RETURN n.`{key}` AS value LIMIT 1\n",
        "            \"\"\")\n",
        "            value = prop_result.single()[\"value\"]\n",
        "            if isinstance(value, str):\n",
        "                property_keys.append(key)\n",
        "        return property_keys\n",
        "\n",
        "# Get string property keys\n",
        "property_keys = get_string_property_keys(driver)\n",
        "print(property_keys)"
      ],
      "metadata": {
        "id": "TfsSS23z8DnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2638a252-c0d7-4c27-e2ab-3cf625959e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sample_name', 'Sex', 'County', 'Population_code', 'Population_name', 'Superpopulation_name', 'Superpopulation_code', 'Data_collections', 'State', 'Cancer_Type', 'Gene', 'alt_allele', 'id', 'Gene_symbol', 'ref_allele', 'Gene_Symbol', 'Gene_name', 'name', 'nucleotide']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_label_string = node_labels[0] if node_labels else None\n",
        "\n",
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(model='text-embedding-3-large',dimensions=384),\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"sample\",\n",
        "    text_node_properties=property_keys,\n",
        "    embedding_node_property=\"embedding\"\n",
        ")\n",
        "vector_retriever = vector_index.as_retriever()\n"
      ],
      "metadata": {
        "id": "DIYo8WXz_2I5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f65b4a-643c-4a25-d624-a0cdc649f4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/openai.py:271: UserWarning: WARNING! dimensions is not default parameter.\n",
            "                    dimensions was transferred to model_kwargs.\n",
            "                    Please confirm that dimensions is what you intended.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "text_embeddings = embeddings.embed_documents(texts)\n",
        "text_embedding_pairs = list(zip(texts, text_embeddings))\n",
        "vectorstore = Neo4jVector.from_embeddings(\n",
        "    text_embedding_pairs, embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "cS8LssfLLmsf",
        "outputId": "0e23a739-89e5-4114-fc23-e5f56d62be90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-2bd86500b133>:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'texts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2bd86500b133>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtext_embedding_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m vectorstore = Neo4jVector.from_embeddings(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Structered Data**"
      ],
      "metadata": {
        "id": "Rh3XdPFkjRjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv\n",
        "!pip install json-repair\n",
        "!pip install  py2neo\n",
        "!pip install neo4j\n",
        "!pip install --upgrade py2neo\n",
        "\n"
      ],
      "metadata": {
        "id": "N3Vfn541VCG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from py2neo import Graph, Node, Relationship\n",
        "#from neo4j_runway import Discovery, GraphDataModeler, PyIngest, UserInput\n",
        "#from neo4j_runway.code_generation import PyIngestConfigGenerator\n",
        "#from neo4j_runway.llm.openai import OpenAIDiscoveryLLM, OpenAIDataModelingLLM\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np\n",
        "from py2neo import Graph, Node, Relationship\n",
        "from neo4j import GraphDatabase\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "#from neo4j_runway import Discovery, GraphDataModeler, IngestionGenerator,PyIngest\n",
        "from IPython.display import display, Markdown, Image\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bgNFx-hPVLFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fd73e7-318b-440e-fd27-1aa50d2203b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel(\"/content/Complete_data_Chr14.csv\", engine='openpyxl')"
      ],
      "metadata": {
        "id": "cCQrdyvrjvuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = Graph(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h7BamXeZV5D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.delete_all()"
      ],
      "metadata": {
        "id": "Dx1w3rxZV-o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list=[\"NA21134\",\"NA21141\",\"NA20845\",\"NA20852\",\"NA20864\",\"NA20869\",\"NA20849\",\"NA20871\",\"NA20851\",\"NA20876\",\"NA20883\",\"NA20888\",\"NA20890\",\"NA20895\",\"NA20903\",\"NA20908\",\"NA20910\",\"NA21088\",\"NA21090\",\"NA21095\",\"NA21103\",\"NA21108\",\"NA21110\",\n",
        "\"NA21115\",\n",
        "\"NA21122\",\n",
        "\"NA21133\",\n",
        "\"NA21127\",\n",
        "\"NA21094\",\n",
        "\"NA21099\",\n",
        "\"NA21102\",\n",
        "\"NA21107\",\n",
        "\"NA21114\",\n",
        "\"NA21119\",\n",
        "\"NA21121\",\n",
        "\"NA21126\",\n",
        "\"NA20856\",\n",
        "\"NA20863\",\n",
        "\"NA20868\",\n",
        "\"NA20870\",\n",
        "\"NA20875\",\n",
        "\"NA20882\",\n",
        "\"NA20887\",\n",
        "\"NA20894\",\n",
        "\"NA20899\",\n",
        "\"NA20902\",\n",
        "\"NA20907\",\n",
        "\"NA21087\",\n",
        "\"NA20846\",\n",
        "\"NA20853\",\n",
        "\"NA20858\",\n",
        "\"NA20872\",\n",
        "\"NA20877\",\n",
        "\"NA20884\",\n",
        "\"NA20889\",\n",
        "\"NA20891\",\n",
        "\"NA21130\",\n",
        "\"NA21135\",\n",
        "\"NA21142\",\n",
        "\"NA20896\",\n",
        "\"NA20904\",\n",
        "\"NA20909\",\n",
        "\"NA20911\",\n",
        "\"NA21089\",\n",
        "\"NA20893\",\n",
        "\"NA21091\",\n",
        "\"NA20898\",\n",
        "\"NA20901\",\n",
        "\"NA20906\",\n",
        "\"NA21086\",\n",
        "\"NA21093\",\n",
        "\"NA20862\",\n",
        "\"NA20867\",\n",
        "\"NA20874\",\n",
        "\"NA20879\",\n",
        "\"NA20881\",\n",
        "\"NA20886\",\n",
        "\"NA20850\",\n",
        "\"NA21137\",\n",
        "\"NA21144\",\n",
        "\"NA21104\",\n",
        "\"NA21109\",\n",
        "\"NA21111\",\n",
        "\"NA21116\",\n",
        "\"NA21123\",\n",
        "\"NA21128\",\n",
        "\"NA21098\",\n",
        "\"NA21101\",\n",
        "\"NA21106\",\n",
        "\"NA21113\",\n",
        "\"NA21118\",\n",
        "\"NA21120\",\n",
        "\"NA21125\",\n",
        "\"NA20847\",\n",
        "\"NA20854\",\n",
        "\"NA20859\",\n",
        "\"NA20861\",\n",
        "\"NA20866\",\n",
        "\"NA20873\",\n",
        "\"NA20878\",\n",
        "\"NA20885\",\n",
        "\"NA20892\",\n",
        "\"NA20897\",\n",
        "\"NA20900\",\n",
        "\"NA20905\",\n",
        "\"NA21092\",\n",
        "\"NA21129\",\n",
        "\"NA21143\",\n",
        "\"NA21097\",\n",
        "\"NA21100\",\n",
        "\"NA21105\",\n",
        "\"NA21112\",\n",
        "\"NA21117\",\n",
        "\"NA21124\"\n",
        "]"
      ],
      "metadata": {
        "id": "zG8v-DD4grsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Chromosome KG insert***"
      ],
      "metadata": {
        "id": "2i6BawHBq42o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_com = pd.read_csv(\"/content/Complete_data_Chr14.csv\")\n"
      ],
      "metadata": {
        "id": "aaoC22pf4ncp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_data(tx, row, sample_id):\n",
        "\n",
        "  # Handle potential NaN values by using Python's pandas to check for NaN\n",
        "\n",
        "    tx.run('''// Merge the Chromosome node\n",
        "          MERGE (chr:Chromosome {number: $CHROM})\n",
        "\n",
        "          // Merge the Variant node (SNP)\n",
        "          MERGE (SNP:SNP {\n",
        "            id: $Existing_variation,\n",
        "            position: $POS,\n",
        "            ref_allele: $REF,\n",
        "            alt_allele: $ALT,\n",
        "            Gene_symbol: $Gene_SYMBOL,\n",
        "            Gene: $Gene,\n",
        "            allele_count: toInteger($AC),\n",
        "            allele_number: toInteger($AN),\n",
        "            depth: toInteger($DP),\n",
        "            overall_af: toFloat($AF),\n",
        "            num_samples: toInteger($NS)\n",
        "          })\n",
        "          // Merge the Sample node for the current sample in the sample_list\n",
        "            MERGE (sample:sample {\n",
        "              Sample_name: $sample_id\n",
        "          })\n",
        "            MERGE (Gene:Gene {\n",
        "              Gene_Symbol: $Gene_SYMBOL,\n",
        "              Gene_name: $Gene\n",
        "\n",
        "          })\n",
        "\n",
        "\n",
        "          // Create the LOCATED_ON relationship between SNP and Chromosome\n",
        "          MERGE (SNP)-[:LOCATED_ON]->(chr)\n",
        "\n",
        "         // Create the LOCATED_ON relationship between SNP and Chromosome\n",
        "          MERGE (SNP)-[:LOCATED_IN]->(Gene)\n",
        "\n",
        "\n",
        "          // Merge Population nodes and create HAS_POPULATION_FREQUENCY relationships\n",
        "          FOREACH (popAF IN [\n",
        "            {code: 'East Asian', af: $EAS_AF},\n",
        "            {code: 'European', af: $EUR_AF},\n",
        "            {code: 'African', af: $AFR_AF},\n",
        "            {code: 'American', af: $AMR_AF},\n",
        "            {code: 'South Asian Ancestry', af: $SAS_AF}\n",
        "          ] |\n",
        "            MERGE (pop:Superpopulation {name: popAF.code})\n",
        "            MERGE (SNP)-[r:HAS_POPULATION_FREQUENCY]->(pop)\n",
        "            SET r.allele_frequency = toFloat(popAF.af)\n",
        "          )\n",
        "\n",
        "          // Merge Allele nodes for Reference and Alternate Alleles\n",
        "          MERGE (refAllele:Allele {nucleotide: $REF})\n",
        "          MERGE (altAllele:Allele {nucleotide: $ALT})\n",
        "\n",
        "\n",
        "          // Create the HAS_GENOTYPE relationship between Sample and Variant\n",
        "          MERGE (sample)-[genotypeRel:HAS_GENOTYPE]->(SNP)\n",
        "          SET genotypeRel.genotype = $NA20846\n",
        "          SET genotypeRel.genotype = $NA20847\n",
        "          SET genotypeRel.genotype = $NA20849\n",
        "          SET genotypeRel.genotype = $NA20850\n",
        "          SET genotypeRel.genotype = $NA20851\n",
        "          SET genotypeRel.genotype = $NA20852\n",
        "          SET genotypeRel.genotype = $NA20853\n",
        "          SET genotypeRel.genotype = $NA20854\n",
        "          SET genotypeRel.genotype = $NA20856\n",
        "          SET genotypeRel.genotype = $NA20858\n",
        "          SET genotypeRel.genotype = $NA20861\n",
        "          SET genotypeRel.genotype = $NA20862\n",
        "          SET genotypeRel.genotype = $NA20863\n",
        "          SET genotypeRel.genotype = $NA20864\n",
        "          SET genotypeRel.genotype = $NA20866\n",
        "          SET genotypeRel.genotype = $NA20867\n",
        "          SET genotypeRel.genotype = $NA20868\n",
        "          SET genotypeRel.genotype = $NA20869\n",
        "          SET genotypeRel.genotype = $NA20870\n",
        "          SET genotypeRel.genotype = $NA20872\n",
        "          SET genotypeRel.genotype = $NA20873\n",
        "          SET genotypeRel.genotype = $NA20874\n",
        "          SET genotypeRel.genotype = $NA20875\n",
        "          SET genotypeRel.genotype = $NA20876\n",
        "          SET genotypeRel.genotype = $NA20877\n",
        "          SET genotypeRel.genotype = $NA20878\n",
        "          SET genotypeRel.genotype = $NA20881\n",
        "          SET genotypeRel.genotype = $NA20882\n",
        "          SET genotypeRel.genotype = $NA20883\n",
        "          SET genotypeRel.genotype = $NA20884\n",
        "          SET genotypeRel.genotype = $NA20885\n",
        "          SET genotypeRel.genotype = $NA20886\n",
        "          SET genotypeRel.genotype = $NA20887\n",
        "          SET genotypeRel.genotype = $NA20888\n",
        "          SET genotypeRel.genotype = $NA20889\n",
        "          SET genotypeRel.genotype = $NA20890\n",
        "          SET genotypeRel.genotype = $NA20891\n",
        "          SET genotypeRel.genotype = $NA20892\n",
        "          SET genotypeRel.genotype = $NA20894\n",
        "          SET genotypeRel.genotype = $NA20895\n",
        "          SET genotypeRel.genotype = $NA20896\n",
        "          SET genotypeRel.genotype = $NA20897\n",
        "          SET genotypeRel.genotype = $NA20899\n",
        "          SET genotypeRel.genotype = $NA20900\n",
        "          SET genotypeRel.genotype = $NA20901\n",
        "          SET genotypeRel.genotype = $NA20902\n",
        "          SET genotypeRel.genotype = $NA20903\n",
        "          SET genotypeRel.genotype = $NA20904\n",
        "          SET genotypeRel.genotype = $NA20905\n",
        "          SET genotypeRel.genotype = $NA20906\n",
        "          SET genotypeRel.genotype = $NA20908\n",
        "          SET genotypeRel.genotype = $NA20910\n",
        "          SET genotypeRel.genotype = $NA20911\n",
        "          SET genotypeRel.genotype = $NA21086\n",
        "          SET genotypeRel.genotype = $NA21087\n",
        "          SET genotypeRel.genotype = $NA21088\n",
        "          SET genotypeRel.genotype = $NA21089\n",
        "          SET genotypeRel.genotype = $NA21090\n",
        "          SET genotypeRel.genotype = $NA21091\n",
        "          SET genotypeRel.genotype = $NA21092\n",
        "          SET genotypeRel.genotype = $NA21093\n",
        "          SET genotypeRel.genotype = $NA21094\n",
        "          SET genotypeRel.genotype = $NA21095\n",
        "          SET genotypeRel.genotype = $NA21097\n",
        "          SET genotypeRel.genotype = $NA21098\n",
        "          SET genotypeRel.genotype = $NA21099\n",
        "          SET genotypeRel.genotype = $NA21100\n",
        "          SET genotypeRel.genotype = $NA21101\n",
        "          SET genotypeRel.genotype = $NA21102\n",
        "          SET genotypeRel.genotype = $NA21103\n",
        "          SET genotypeRel.genotype = $NA21104\n",
        "          SET genotypeRel.genotype = $NA21105\n",
        "          SET genotypeRel.genotype = $NA21106\n",
        "          SET genotypeRel.genotype = $NA21107\n",
        "          SET genotypeRel.genotype = $NA21108\n",
        "          SET genotypeRel.genotype = $NA21109\n",
        "          SET genotypeRel.genotype = $NA21110\n",
        "          SET genotypeRel.genotype = $NA21111\n",
        "\n",
        "\n",
        "\n",
        "''',{\n",
        "        **row,  # Include all the other values from the row for SNP, Chromosome, etc.\n",
        "        \"sample_id\": sample_id  })\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in data_com.iterrows():\n",
        "        for sample_id in sample_list:\n",
        "             session.write_transaction(insert_data, row.to_dict(),sample_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "7HrqneTN_Yan",
        "outputId": "6099c917-141d-446e-d24a-8fc160254d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-955653144e6a>:148: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-18-955653144e6a>:151: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data, row.to_dict(),sample_id)\n",
            "ERROR:neo4j.io:Failed to write data to connection IPv4Address(('58ab470f.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('35.241.237.34', 7687)))\n",
            "ERROR:neo4j.io:Failed to write data to connection ResolvedIPv4Address(('35.241.237.34', 7687)) (ResolvedIPv4Address(('35.241.237.34', 7687)))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-955653144e6a>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_com\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m              \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_meta.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mwarning_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_without_warning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36mwrite_transaction\u001b[0;34m(self, transaction_function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mMethod\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mrenamed\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_write\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \"\"\"\n\u001b[0;32m--> 839\u001b[0;31m         return self._run_transaction(\n\u001b[0m\u001b[1;32m    840\u001b[0m             \u001b[0mWRITE_ACCESS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0mTelemetryAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTX_FUNC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36m_run_transaction\u001b[0;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                 self._open_transaction(\n\u001b[0m\u001b[1;32m    564\u001b[0m                     \u001b[0mtx_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mManagedTransaction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtelemetry_sent\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36m_open_transaction\u001b[0;34m(self, tx_cls, access_mode, api, metadata, timeout, api_success_cb)\u001b[0m\n\u001b[1;32m    444\u001b[0m         )\n\u001b[1;32m    445\u001b[0m         \u001b[0mbookmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bookmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         self._transaction._begin(\n\u001b[0m\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpersonated_user\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/work/transaction.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, database, imp_user, bookmarks, access_mode, metadata, timeout, notifications_min_severity, notifications_disabled_classifications, pipelined)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpipelined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_handling_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_handling_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_result_on_closed_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNeo4jError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionExpired\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m                 \u001b[0mdetail_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m                 \u001b[0mdetail_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdetail_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                 \u001b[0msummary_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msummary_delta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;31m# Receive exactly one message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         tag, fields = self.inbox.pop(\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydration_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, hydration_hooks)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_one_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_structure_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36m_buffer_one_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;31m# Determine the chunk size and skip noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0mreceive_into_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_u16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mreceive_into_buffer\u001b[0;34m(sock, buffer, n_bytes)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             n = sock.recv_into(\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_async_compat/network/_bolt_socket.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/neo4j/_async_compat/network/_bolt_socket.py\u001b[0m in \u001b[0;36m_wait_for_io\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mdeadline_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pd.read_csv(\"/content/Harris country samples.csv\")\n",
        "\n",
        "\n",
        "def insert_data1(tx, row):\n",
        "\n",
        "  # Handle potential NaN values by using Python's pandas to check for NaN\n",
        "\n",
        "    tx.run('''//\n",
        "          MERGE (sample:sample {\n",
        "            Sample_name: $Sample_name\n",
        "          })\n",
        "           MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "          MERGE (county:county {\n",
        "            County: \"Harris\",\n",
        "            County_FIPS: 48201\n",
        "          })\n",
        "         MERGE (Population:Population {\n",
        "           Population_code: $Population_code,\n",
        "           Population_name: $Population_name\n",
        "         })\n",
        "\n",
        "         MERGE (Superpopulation:Superpopulation {\n",
        "           Superpopulation_code: $Superpopulation_code,\n",
        "           Superpopulation_name: $Superpopulation_name\n",
        "         })\n",
        "\n",
        "          MERGE (Data_collections:Data_collections {\n",
        "           Data_collections: $Data_collections\n",
        "         })\n",
        "\n",
        "          MERGE (sample)-[:BELONGS_TO]->(Population)\n",
        "          MERGE (sample)-[:BELONG_TO_SEX]->(Sex)\n",
        "          MERGE (Population)-[:PART_OF]->(Superpopulation)\n",
        "          MERGE (sample)-[:IN_DATA_COLLECTION]->(Data_collections)\n",
        "          MERGE (sample)-[c:COLLECT_FROM]->(county)\n",
        "          SET c.Years_Range = \"2008-2021\"\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in data1.iterrows():\n",
        "        session.write_transaction(insert_data1, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0lDBWxnsiSI",
        "outputId": "61310771-5059-4743-ff91-db3bd244e847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-10accd944eb8>:46: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-15-10accd944eb8>:48: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data1, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NCI DATA TABLE**"
      ],
      "metadata": {
        "id": "t56ArpipgaTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCI = pd.read_excel(\"/content/Harris_Texas_Cancer_statistics.xlsx\", engine='openpyxl')\n",
        "\n",
        "def insert_NCI(tx, row):\n",
        "\n",
        "  # Handle potential NaN values by using Python's pandas to check for NaN\n",
        "\n",
        "    tx.run('''//\n",
        "          MERGE (state:state {\n",
        "            State: $State\n",
        "          })\n",
        "\n",
        "          MERGE (county:county {\n",
        "            County: $County,\n",
        "            County_FIPS: $County_FIPS\n",
        "          })\n",
        "\n",
        "          MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "          MERGE (Superpopulation:Superpopulation {\n",
        "                    Superpopulation_code: $Race\n",
        "         })\n",
        "\n",
        "         MERGE (Cancer_type:Cancer_Type {\n",
        "           Cancer_Type: $Cancer_Type\n",
        "         })\n",
        "\n",
        "          MERGE (state)-[:HAS_COUNTY]->(county)\n",
        "          MERGE (Cancer_type)-[:FROM_SEX]->(Sex)\n",
        "          MERGE (Cancer_type)-[:FROM_RACE]->(Superpopulation)\n",
        "          MERGE (Superpopulation)-[:IN]->(county)\n",
        "          MERGE (Cancer_type)-[r:OCCUR_IN]->(county)\n",
        "          SET r.Years_Range = $Years_range\n",
        "          SET r.cancer_cases = $number_of_new_cancer_cases_diagnosed\n",
        "          SET r.Age_Adjusted_Rate_per_100000 = $Age_Adjusted_Rate_per_100000\n",
        "          SET r.Cancer_Type = $Cancer_Type\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in NCI.iterrows():\n",
        "        session.write_transaction(insert_NCI, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oOc2as0gZZ_",
        "outputId": "076fe327-eee0-4ae8-8cd2-ee9ad2161196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-18e0b07c7fac>:49: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-16-18e0b07c7fac>:51: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_NCI, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***SDOH DATA***"
      ],
      "metadata": {
        "id": "F86RE2D1giDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Education = pd.read_excel(\"/content/ Harris_Texas_Education.xlsx\", engine='openpyxl')\n",
        "\n",
        "\n",
        "def insert_data_Education(tx, row):\n",
        "\n",
        "  # Handle potential NaN values by using Python's pandas to check for NaN\n",
        "\n",
        "    tx.run('''//\n",
        "\n",
        "           MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "         MERGE (county:county {\n",
        "            County: \"Harris\",\n",
        "            County_FIPS: 48201\n",
        "          })\n",
        "          MERGE (state:state {\n",
        "            State: $State\n",
        "          })\n",
        "\n",
        "         MERGE (Education:Education {\n",
        "           Education: $Education\n",
        "\n",
        "\n",
        "         })\n",
        "\n",
        "         MERGE (statistic:statistic {\n",
        "           statistic: $Percent\n",
        "          })\n",
        "\n",
        "\n",
        "          MERGE (state)-[:HAS_COUNTY]->(county)\n",
        "          MERGE (statistic)-[r:FOR_SEX]->(Sex)\n",
        "          SET r.Years_Range = $Years_range\n",
        "          MERGE (statistic)-[m:FOR_EDUCATION_LEVEL]->(Education)\n",
        "          SET m.Years_Range = $Years_range\n",
        "          MERGE (statistic)-[n:RELATES_TO]->(county)\n",
        "          SET n.Years_Range = $Years_range\n",
        "\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in Education.iterrows():\n",
        "        session.write_transaction(insert_data_Education, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbC6eGvRgdwn",
        "outputId": "d1aa13b1-7270-4d53-fdb0-0d33734621cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9e9bfc287a3e>:47: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-8-9e9bfc287a3e>:49: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data_Education, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Income = pd.read_excel(\"/content/ Harris_Texas_Income.xlsx\", engine='openpyxl')\n",
        "\n",
        "\n",
        "def insert_data_Income(tx, row):\n",
        "\n",
        "  # Handle potential NaN values by using Python's pandas to check for NaN\n",
        "\n",
        "    tx.run('''//\n",
        "\n",
        "           MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "          MERGE (county:county {\n",
        "            County: $County,\n",
        "            County_FIPS: $County_FIPS\n",
        "          })\n",
        "          MERGE (state:state {\n",
        "            State: $State\n",
        "          })\n",
        "          MERGE (Income:Income {\n",
        "             Income: $Income,\n",
        "             Dollars: $Dollars\n",
        "          })\n",
        "          MERGE (Income)-[n:INCOME_FOR_SEX]->(Sex)\n",
        "          SET n.Years_Range = $Years_range\n",
        "          MERGE (Income)-[m:INCOME_FOR_COUNTY]->(county)\n",
        "          SET m.Years_Range = $Years_range\n",
        "\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in Income.iterrows():\n",
        "        session.write_transaction(insert_data_Income, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtN11OBXlaub",
        "outputId": "a378b986-d95d-489b-ca28-778e909b28ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-be1d65367a20>:36: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-14-be1d65367a20>:38: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data_Income, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Crowding = pd.read_excel(\"/content/Harris_Texas_crowding.xlsx\", engine='openpyxl')\n",
        "\n",
        "\n",
        "def insert_data_Crowding(tx, row):\n",
        "\n",
        "  # Handle potential NaN values by using Python's pandas to check for NaN\n",
        "\n",
        "    tx.run('''//\n",
        "\n",
        "           MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "          MERGE (county:county {\n",
        "            County: $County,\n",
        "            County_FIPS: $County_FIPS\n",
        "          })\n",
        "          MERGE (state:state {\n",
        "            State: $State\n",
        "          })\n",
        "          MERGE (Crowding:Crowding {\n",
        "             Crowding: $Crowding,\n",
        "             Percent: $Percent,\n",
        "             Years_range: $Years_range\n",
        "          })\n",
        "          MERGE (Crowding)-[:CROWDING_FOR_SEX]->(Sex)\n",
        "          MERGE (Crowding)-[:CROWDING_BY_COUNTY]->(county)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in Crowding.iterrows():\n",
        "        session.write_transaction(insert_data_Crowding, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht9h82B6rEYf",
        "outputId": "b1cc7b7f-2d73-4fed-d01e-6ce98cb25f6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-e8afa6c4de7f>:37: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-8-e8afa6c4de7f>:39: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data_Crowding, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Superpopulation = pd.read_excel(\"/content/Harris_Texas_Population.xlsx\", engine='openpyxl')\n",
        "\n",
        "\n",
        "def insert_data_Superpopulation(tx, row):\n",
        "\n",
        "\n",
        "    tx.run('''//\n",
        "\n",
        "           MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "          MERGE (county:county {\n",
        "            County: $County,\n",
        "            County_FIPS: $County_FIPS\n",
        "          })\n",
        "          MERGE (state:state {\n",
        "            State: $State\n",
        "          })\n",
        "\n",
        "          MERGE (Superpopulation:Superpopulation {\n",
        "           Superpopulation_code: \"\",\n",
        "           Superpopulation_name: $Population\n",
        "         })\n",
        "\n",
        "          MERGE (Superpopulation)-[n:Superpopulation_STATISTIC_FOR_SEX]->(Sex)\n",
        "          SET n.Years_Range = $Years_range\n",
        "          SET n.Percent= $Percent\n",
        "          MERGE (Superpopulation)-[m:Superpopulation_STATISTIC_BY_COUNTY]->(county)\n",
        "          SET m.Years_Range = $Years_range\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in Superpopulation.iterrows():\n",
        "        session.write_transaction(insert_data_Superpopulation, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-2NkUlps2Cn",
        "outputId": "2b6e50fb-893b-4452-c4df-6a886f6df800"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4a35ceb507e1>:41: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-18-4a35ceb507e1>:43: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data_Superpopulation, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Sex = pd.read_excel(\"/content/Harris_Texas_sex.xlsx\", engine='openpyxl')\n",
        "\n",
        "\n",
        "def insert_data_Sex(tx, row):\n",
        "\n",
        "\n",
        "    tx.run('''//\n",
        "\n",
        "           MERGE (Sex:Sex {\n",
        "            Sex: $Sex\n",
        "         })\n",
        "          MERGE (county:county {\n",
        "            County: $County,\n",
        "            County_FIPS: $County_FIPS\n",
        "          })\n",
        "          MERGE (state:state {\n",
        "            State: $State\n",
        "          })\n",
        "\n",
        "          MERGE (Sex)-[n:Population_cancer_Percent_IN_COUNTY]->(county)\n",
        "          SET n.Population_cancer_Percent = $Population_cancer_Percent\n",
        "          SET n.Years_Range = $Years_range\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''',row)\n",
        "\n",
        "with GraphDatabase.driver(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"])) as driver:\n",
        "    driver.verify_connectivity()\n",
        "\n",
        "with driver.session() as session:\n",
        "    for _, row in Sex.iterrows():\n",
        "        session.write_transaction(insert_data_Sex, row.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPIPGZmlwId3",
        "outputId": "adcf949e-c09f-4593-aa1c-ef04019010b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-752d0825972a>:34: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
            "  with driver.session() as session:\n",
            "<ipython-input-16-752d0825972a>:36: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_data_Sex, row.to_dict())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LLM RAG***"
      ],
      "metadata": {
        "id": "6ADoHtvws25J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"], temperature=0.5\n",
        ")\n",
        "\n",
        "graph = Neo4jGraph(\n",
        "    url=os.environ[\"NEO4J_URI\"],\n",
        "    username=\"neo4j\",\n",
        "    password=os.environ[\"NEO4J_PASSWORD\"],\n",
        ")\n",
        "\n",
        "CYPHER_GENERATION_TEMPLATE = \"\"\"\n",
        "You are an expert Neo4j Developer translating user questions into Cypher to answer questions about genetics, SNP data and cancer provide recommendations.\n",
        "Convert the user's question based on the schema to neo4j cypher query that return the entity's properties and relationships.\n",
        "\n",
        "Instructions:\n",
        "Use the provided entity's properties and relationships in the schema:\n",
        "\n",
        "This knowledge graph is structured around several key entities and the relationships between them. Here is a description of each entity and the relationships it has:\n",
        "\n",
        "Entities (Nodes):\n",
        "SNP (Single Nucleotide Polymorphism):\n",
        "\n",
        "A genetic variation identified by a change in a single nucleotide.\n",
        "Relationships:\n",
        "LOCATED_ON → Chromosome: Indicates the chromosome where the SNP is located.\n",
        "HAS_POPULATION_FREQUENCY → Population: Represents the population frequency data related to the SNP.\n",
        "LOCATED_IN → Gene: Identifies the gene in which the SNP is located.\n",
        "HAS_GENOTYPE → sample: Links the SNP to a specific sample and its genotype.\n",
        "Chromosome:\n",
        "\n",
        "Represents the chromosome in which a SNP is located.\n",
        "Relationships:\n",
        "LOCATED_ON ← SNP: A SNP is located on this chromosome.\n",
        "Gene:\n",
        "\n",
        "Represents the gene associated with a particular SNP.\n",
        "Relationships:\n",
        "LOCATED_IN ← SNP: The SNP is located within this gene.\n",
        "Population:\n",
        "\n",
        "Represents a specific population in which SNP data is available.\n",
        "Relationships:\n",
        "HAS_POPULATION_FREQUENCY ← SNP: The population frequency of a specific SNP.\n",
        "PART_OF → Superpopulation: This population is part of a larger superpopulation.\n",
        "Superpopulation:\n",
        "\n",
        "Represents a broader superpopulation that contains several smaller populations.\n",
        "Relationships:\n",
        "PART_OF ← Population: Indicates that a population is part of this superpopulation.\n",
        "\n",
        "sample:\n",
        "\n",
        "Represents a biological sample used in genomic studies.\n",
        "Relationships:\n",
        "HAS_GENOTYPE → SNP: Links the sample to the specific SNP and its genotype.\n",
        "BELONGS_TO → Population: The sample belongs to a specific population.\n",
        "COLLECT_FROM → county: Indicates the county where the sample was collected.\n",
        "BELONG_TO_SEX → Sex: Indicates the sex associated with the sample.\n",
        "\n",
        "Sex:\n",
        "\n",
        "Represents the sex (male/female) of a sample.\n",
        "Relationships:\n",
        "BELONG_TO_SEX ← sample: The sample is associated with a specific sex.\n",
        "FROM_SEX → county: Connects the sex to the county in which samples were collected.\n",
        "\n",
        "county:\n",
        "\n",
        "Represents a geographic region (county) where samples were collected.\n",
        "Relationships:\n",
        "COLLECT_FROM ← sample: Samples are collected from this county.\n",
        "OCCUR_IN → Cancer_Type: This county is associated with certain cancer types.\n",
        "FROM_SEX ← Sex: Indicates the sex distribution for the samples collected from this county.\n",
        "HAS_COUNTY → State: This county is located in a specific state.\n",
        "State:\n",
        "\n",
        "Represents a geographic state that contains various counties.\n",
        "Relationships:\n",
        "HAS_COUNTY ← county: This state contains the referenced county.\n",
        "Cancer Type:\n",
        "\n",
        "Represents different types of cancers observed in a population.\n",
        "Relationships:\n",
        "OCCUR_IN ← county: The county is associated with the occurrence of this cancer type.\n",
        "Data_collections:\n",
        "\n",
        "Represents different genomic or population data collections.\n",
        "Relationships:\n",
        "IN_DATA_COLLECTION → sample: The sample belongs to a specific data collection.\n",
        "\n",
        "\n",
        "\n",
        "Examples:\n",
        "For the quastion \"What is the best cancer treatment?\" use only this cypher:\n",
        "MATCH (n:Treatment)\n",
        "RETURN n LIMIT 25;\n",
        "\n",
        "\n",
        "For the quastion \"what is the top 2 letal cancer in harris texas?\" use only this cypher:\n",
        "MATCH (c:Cancer_Type)-[r:OCCUR_IN]->(co:county)<-[:HAS_COUNTY]-(s:state)\n",
        "WHERE co.county = 'Harris' AND s.State = 'Texas'\n",
        "RETURN c.Cancer_Type, r.cancer_cases\n",
        "ORDER BY r.cancer_cases DESC\n",
        "LIMIT X;\n",
        "\n",
        "X is by defult is 3 and specify the top 3 cancer types.\n",
        "\n",
        "For  quastions about SNP use only this cypher:\n",
        "MATCH (s:sample)-[:HAS_GENOTYPE]->(snp:SNP)\n",
        "RETURN snp.id, COUNT(s) as sample_count\n",
        "ORDER BY sample_count DESC\n",
        "LIMIT X;\n",
        "and take the 'snp.id' from the Full context as an answer.\n",
        "\n",
        "For  quastion:\"what is the most deadlist genotype?\":\n",
        "MATCH (s:sample)-[hg:HAS_GENOTYPE]->(snp:SNP)\n",
        "RETURN hg.genotype, COUNT(s) as sample_count\n",
        "ORDER BY sample_count DESC\n",
        "LIMIT 1;\n",
        "and take the 'hg.genotype' and 'sample_count' from the Full context.\n",
        "answer: \"The most deadlist genotype is 'hg.genotype' with 'sample_count' samples\".\n",
        "\n",
        "\n",
        "Schema: {schema}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "cypher_generation_prompt = PromptTemplate(\n",
        "    template=CYPHER_GENERATION_TEMPLATE,\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        ")\n",
        "\n",
        "cypher_chain = GraphCypherQAChain.from_llm(\n",
        "    llm,\n",
        "    graph=graph,\n",
        "    cypher_prompt=cypher_generation_prompt,\n",
        "    allow_dangerous_requests=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "graph_data= cypher_chain.invoke({\"query\": \"what is the most deadlist genotype in texas?\"})\n",
        "\n",
        "print(graph_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr-ZtYVSn_OE",
        "outputId": "7c519083-537d-46ae-f812-1d7d1f5cec9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mcypher\n",
            "MATCH (s:sample)-[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "RETURN hg.genotype, COUNT(s) as sample_count\n",
            "ORDER BY sample_count DESC\n",
            "LIMIT 1;\n",
            "\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'hg.genotype': '0|0', 'sample_count': 24623}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'query': 'what is the most deadlist genotype?', 'result': \"I don't know the answer.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "import json\n",
        "\n",
        "\n",
        "# Create a Neo4j driver instance\n",
        "driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
        "                os.environ[\"NEO4J_PASSWORD\"]))\n",
        "\n",
        "def export_nodes(session, output_file):\n",
        "    # Query to get all nodes\n",
        "    cypher_query = \"\"\"\n",
        "    MATCH (n)\n",
        "    RETURN id(n) AS node_id, labels(n) AS labels, properties(n) AS properties\n",
        "    \"\"\"\n",
        "    result = session.run(cypher_query)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Nodes:\\n\")\n",
        "        for record in result:\n",
        "            node_data = {\n",
        "                'node_id': record['node_id'],\n",
        "                'labels': record['labels'],\n",
        "                'properties': record['properties']\n",
        "            }\n",
        "            f.write(json.dumps(node_data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "def export_relationships(session, output_file):\n",
        "    # Query to get all relationships\n",
        "    cypher_query = \"\"\"\n",
        "    MATCH (n)-[r]->(m)\n",
        "    RETURN id(r) AS rel_id, type(r) AS type, id(n) AS start_node_id, id(m) AS end_node_id, properties(r) AS properties\n",
        "    \"\"\"\n",
        "    result = session.run(cypher_query)\n",
        "\n",
        "    with open(output_file, 'a', encoding='utf-8') as f:\n",
        "        f.write(\"\\nRelationships:\\n\")\n",
        "        for record in result:\n",
        "            rel_data = {\n",
        "                'rel_id': record['rel_id'],\n",
        "                'type': record['type'],\n",
        "                'start_node_id': record['start_node_id'],\n",
        "                'end_node_id': record['end_node_id'],\n",
        "                'properties': record['properties']\n",
        "            }\n",
        "            f.write(json.dumps(rel_data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "def export_knowledge_graph(output_file):\n",
        "    with driver.session() as session:\n",
        "        export_nodes(session, output_file)\n",
        "        export_relationships(session, output_file)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    output_file = 'knowledge_graph_export.txt'\n",
        "    export_knowledge_graph(output_file)\n",
        "    print(f\"Knowledge graph exported to {output_file}\")\n",
        "    driver.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6jPlFwtvOKM",
        "outputId": "cd4a4bc0-3feb-4215-c73b-92c41cf8acd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:neo4j.io:Failed to write data to connection ResolvedIPv4Address(('35.241.237.34', 7687)) (ResolvedIPv4Address(('35.241.237.34', 7687)))\n",
            "ERROR:neo4j.io:Failed to write data to connection IPv4Address(('58ab470f.databases.neo4j.io', 7687)) (ResolvedIPv4Address(('35.241.237.34', 7687)))\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 12, offset: 26} for query: '\\n    MATCH (n)\\n    RETURN id(n) AS node_id, labels(n) AS labels, properties(n) AS properties\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 12, offset: 35} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN id(r) AS rel_id, type(r) AS type, id(n) AS start_node_id, id(m) AS end_node_id, properties(r) AS properties\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 46, offset: 69} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN id(r) AS rel_id, type(r) AS type, id(n) AS start_node_id, id(m) AS end_node_id, properties(r) AS properties\\n    '\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 3, column: 70, offset: 93} for query: '\\n    MATCH (n)-[r]->(m)\\n    RETURN id(r) AS rel_id, type(r) AS type, id(n) AS start_node_id, id(m) AS end_node_id, properties(r) AS properties\\n    '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Knowledge graph exported to knowledge_graph_export.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#USE FOR CSV FILE\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Step 1: Load the CSV file\n",
        "csv_file_path = '/content/Complete_data_Chr14.csv'\n",
        "df = pd.read_csv(csv_file_path, sep=';',on_bad_lines='skip', engine='python')\n",
        "\n",
        "# Step 2: Concatenate the text data\n",
        "# Assuming the text you want to process is in a column named 'text'\n",
        "# Modify 'text' to the appropriate column name in your CSV\n",
        "column_name = df.columns[0]\n",
        "text_data = \" \".join(df[column_name].astype(str).tolist())\n",
        "\n",
        "# Create a Document object from the text data\n",
        "docs = [Document(page_content=text_data)]\n",
        "\n",
        "# Step 3: Split the text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(documents=docs)\n",
        "documents = documents[:100]\n",
        "\n"
      ],
      "metadata": {
        "id": "F0dkBxrXwQLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def RAG(question: str):\n",
        "\n",
        "  # Initialize OpenAI Embeddings\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  global documents\n",
        "  # Generate embeddings for the documents\n",
        "  texts = [doc.page_content for doc in documents]\n",
        "  document_embeddings = embeddings.embed_documents(texts)\n",
        "\n",
        "  # Create Document objects with embeddings\n",
        "  documents = [Document(page_content=text) for text in texts]\n",
        "\n",
        "  # Create FAISS index\n",
        "  faiss_index = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "  # Save the index (optional)\n",
        "  faiss_index.save_local(\"faiss_index\")\n",
        "\n",
        "  # Perform similarity search\n",
        "  query = question\n",
        "  similar_docs = faiss_index.similarity_search(query, k=5)\n",
        "\n",
        "  search_results = []\n",
        "  for idx, doc in enumerate(similar_docs):\n",
        "      result = {\n",
        "          'document_number': idx + 1,\n",
        "          'content': doc.page_content,\n",
        "          'metadata': doc.metadata  # Include metadata if available\n",
        "      }\n",
        "      search_results.append(result)\n",
        "\n",
        "\n",
        "  #print(\"Search Results Stored in Variable:\")\n",
        "  #for result in search_results:\n",
        "      #print(f\"\\nDocument {result['document_number']}:\")\n",
        "      #print(result['content'])\n",
        "  return search_results"
      ],
      "metadata": {
        "id": "6zUDxJtpkEyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_retriever(question: str):\n",
        "    #graph_data = graph_retriever(question)\n",
        "    rag_data = RAG(question)\n",
        "    vector_data = []\n",
        "    for el in vector_retriever.invoke(question):\n",
        "        if isinstance(el.page_content, list):\n",
        "            content = \" \".join(el.page_content)\n",
        "        else:\n",
        "            content = el.page_content\n",
        "        vector_data.append(content)\n",
        "\n",
        "    final_data = f\"\"\"Graph data:\n",
        "{graph_data}, {rag_data},\n",
        "vector data:\n",
        "{\"#Document \".join(vector_data)}\n",
        "    \"\"\"\n",
        "    print(final_data)\n",
        "    return final_data"
      ],
      "metadata": {
        "id": "HMURhATQt-gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Use natural language and be concise.\n",
        "Answer:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "        {\n",
        "            \"context\": full_retriever,\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "mheBe094uDDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(input=\"what is the most deadlist genotype?\")"
      ],
      "metadata": {
        "id": "XDTrsPS_uH4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "smVUPAWZveJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Set up OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "\n",
        "# Neo4j connection details\n",
        "NEO4J_URI = os.environ[\"NEO4J_URI\"]\n",
        "NEO4J_USER = 'neo4j'\n",
        "NEO4J_PASSWORD = os.environ[\"NEO4J_PASSWORD\"]\n",
        "\n",
        "# Initialize Neo4j driver\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "\n",
        "# Initialize OpenAI LLM\n",
        "llm = OpenAI(temperature=0.0)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = OpenAIEmbeddings()  # Or use SentenceTransformer for local models\n",
        "\n",
        "\n",
        "\n",
        "# Define prompt template\n",
        "template = \"\"\"\n",
        "You are an expert assistant. Use the context below to answer the user's question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "def get_relevant_data(question):\n",
        "    with driver.session() as session:\n",
        "        keywords = extract_keywords(question)\n",
        "        records = []\n",
        "        for keyword in keywords:\n",
        "            cypher_query = \"\"\"\n",
        "            MATCH (n)\n",
        "            WHERE any(prop IN $searchProps WHERE toString(n[prop]) CONTAINS $keyword)\n",
        "            RETURN n, labels(n) AS labels, n AS properties\n",
        "            \"\"\"\n",
        "            searchProps = ['id', 'name', 'gene_name', 'population_name', 'sample_id']\n",
        "            result = session.run(cypher_query, searchProps=searchProps, keyword=keyword)\n",
        "            records.extend(result.data())\n",
        "    return records\n",
        "\n",
        "def extract_keywords(text):\n",
        "    import re\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Convert to lowercase and split into words\n",
        "    words = text.lower().split()\n",
        "    # Remove common stop words\n",
        "    stop_words = {'what', 'is', 'the', 'a', 'an', 'of', 'and', 'or', 'in', 'to', 'how', 'do', 'i', 'on', 'for'}\n",
        "    keywords = [word for word in words if word not in stop_words]\n",
        "    return keywords\n",
        "\n",
        "\n",
        "def format_context(data):\n",
        "    \"\"\"\n",
        "    Format the retrieved data into a context string for the LLM.\n",
        "    \"\"\"\n",
        "    context = \"\"\n",
        "    for record in data:\n",
        "        name = record.get('name', '')\n",
        "        labels = record.get('labels', [])\n",
        "        properties = record.get('properties', {})\n",
        "        context += f\"Name: {name}\\nLabels: {labels}\\nProperties: {properties}\\n\\n\"\n",
        "    return context\n",
        "\n",
        "def qa_system(question):\n",
        "    \"\"\"\n",
        "    Main function to handle the Q&A process.\n",
        "    \"\"\"\n",
        "    # Step 1: Retrieve relevant data from Neo4j\n",
        "    data = get_relevant_data(question)\n",
        "    if not data:\n",
        "        return \"I'm sorry, I couldn't find any information related to your question.\"\n",
        "\n",
        "    # Step 2: Format the context\n",
        "    context = format_context(data)\n",
        "\n",
        "    # Step 3: Prepare the prompt\n",
        "    formatted_prompt = prompt.format(context=context, question=question)\n",
        "\n",
        "    # Step 4: Generate answer using the LLM\n",
        "    answer = llm(formatted_prompt)\n",
        "\n",
        "    return answer.strip()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    user_question = input(\"Please enter your question: \")\n",
        "    response = qa_system(user_question)\n",
        "    print(\"\\nAnswer:\")\n",
        "    print(response)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vj15YYoSoCoy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d8f1bf0f-e494-473f-b339-734a875ad213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentence_transformers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fc5b435576bb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Set up OpenAI API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CHATING WITH THE GRAPH***"
      ],
      "metadata": {
        "id": "xar_iRBdBMVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Langchain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        ")\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "llm_type = os.getenv(\"LLM_TYPE\", \"GPT_MODEL\")\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "q7vDqL8nulS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Vector search***"
      ],
      "metadata": {
        "id": "HgTBEdUmCfKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: list[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the Individual, Cancer Type, Genetic Variant, Pathway, SDOH, Geographical Location, Cancer Incidence, Survival Rate and cancer related entities \"\n",
        "        \"that appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting All the Individual, Cancer Type, Genetic Variant, Pathway, SDOH, Geographical Location, Cancer Incidence, Survival Rate and cancer related entities from the text.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following \"\n",
        "            \"input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "entity_chain = prompt | llm.with_structured_output(Entities)"
      ],
      "metadata": {
        "id": "yxWRkkvoC0SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_chain.invoke({\"question\": \"Who is Hespanic?\"}).names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mIQoaYGmC8W1",
        "outputId": "fac4d3ad-763e-4dae-a37f-d17d81d7ac42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hespanic'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "הפונקציה למטה אמורה להחזיר את השם של היישות שיש לה ערך שווה לproprtyvalue"
      ],
      "metadata": {
        "id": "Sj0Sag5iNH3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entity_label_by_property_value(driver, property_value):\n",
        "    with driver.session() as session:\n",
        "        query = \"\"\"\n",
        "        MATCH (n)\n",
        "        WHERE any(propName IN keys(n) WHERE n[propName] = $property_value)\n",
        "        RETURN DISTINCT labels(n) AS node_labels\n",
        "        \"\"\"\n",
        "        result = session.run(query, property_value=property_value)\n",
        "        labels = set()\n",
        "        for record in result:\n",
        "            for label in record['node_labels']:\n",
        "                labels.add(label)\n",
        "        return list(labels)\n",
        "\n",
        "# Example usage:\n",
        "def get_entity_label_by_property(property_value):\n",
        "\n",
        "\n",
        "    driver = GraphDatabase.driver(uri=os.environ[\"NEO4J_URI\"],auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"]))\n",
        "\n",
        "\n",
        "\n",
        "    labels = get_entity_label_by_property_value(driver, property_value)\n",
        "    return labels\n",
        "\n",
        "    driver.close()"
      ],
      "metadata": {
        "id": "dL6MP0vrLdvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import  Driver,GraphDatabase\n",
        "from google.colab import userdata\n",
        "\n",
        "def initialize_fulltext_index(driver, label):\n",
        "    with driver.session() as session:\n",
        "        if isinstance(label, list):\n",
        "          label = label[0]\n",
        "\n",
        "\n",
        "        # Step 1: Retrieve all property keys for nodes with the given label\n",
        "        result = session.run(f\"\"\"\n",
        "        MATCH (n:{label})\n",
        "        UNWIND keys(n) AS key\n",
        "        RETURN DISTINCT key\n",
        "        \"\"\")\n",
        "        properties = [record['key'] for record in result]\n",
        "\n",
        "        if properties:\n",
        "            # Step 2: Construct the CREATE INDEX statement\n",
        "            props_list = ', '.join([f\"n.{prop}\" for prop in properties])\n",
        "            index_name = f\"{label}_fulltext_index\"\n",
        "            query = f\"\"\"\n",
        "            CREATE FULLTEXT INDEX {index_name} IF NOT EXISTS\n",
        "            FOR (n:{label})\n",
        "            ON EACH [{props_list}]\n",
        "            \"\"\"\n",
        "            # Step 3: Execute the index creation query\n",
        "            session.run(query)\n",
        "            print(f\"Full-text index '{index_name}' created on properties: {props_list}\")\n",
        "        else:\n",
        "            print(f\"No properties found for label '{label}'\")\n"
      ],
      "metadata": {
        "id": "DO7qWhmODZ17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    if not words:\n",
        "        return \"\"\n",
        "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
        "    print(f\"Generated Query: {full_text_query}\")\n",
        "    print(full_text_query)\n",
        "    return full_text_query.strip()\n",
        "\n",
        "\n",
        "# Fulltext index query\n",
        "def graph_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "\n",
        "    for entity in entities.names:\n",
        "        print(entity)\n",
        "        response = kg.query(\n",
        "            f\"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {{limit:2}})\n",
        "        YIELD node, score\n",
        "        CALL {{\n",
        "          WITH node\n",
        "          MATCH (names{{id:\"{entity}\"}})-[r:!MENTIONS]->(neighbor)\n",
        "          RETURN names.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "          UNION ALL\n",
        "          WITH node\n",
        "          MATCH (names{{id:\"{entity}\"}})<-[r:!MENTIONS]-(neighbor)\n",
        "          RETURN neighbor.id + ' - ' + type(r) + ' -> ' + names.id AS output\n",
        "        }}\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        print(response)\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result"
      ],
      "metadata": {
        "id": "ORNMusBhGh-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Superpopulation graph_retriver***"
      ],
      "metadata": {
        "id": "-l1AxHoRH5fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    if not words:\n",
        "        return \"\"\n",
        "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
        "    print(f\"Generated Query: {full_text_query}\")\n",
        "    print(full_text_query)\n",
        "    return full_text_query.strip()\n",
        "\n",
        "\n",
        "# Fulltext index query\n",
        "def graph_retriever_Superpopulation(question: str) -> str:\n",
        "    kg = Graph(os.environ[\"NEO4J_URI\"], auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"]))\n",
        "\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "\n",
        "    for entity in entities.names:\n",
        "        print(entity)\n",
        "        response = kg.query(\n",
        "            f\"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {{limit:2}})\n",
        "        YIELD node, score\n",
        "        CALL {{\n",
        "          WITH node\n",
        "          MATCH (Superpopulation{{Superpopulation_name:\"{entity}\"}})-[r:!MENTIONS]->(neighbor)\n",
        "          RETURN Superpopulation.Superpopulation_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\n",
        "          UNION ALL\n",
        "          WITH node\n",
        "          MATCH (Superpopulation{{Superpopulation_name:\"{entity}\"}})<-[r:!MENTIONS]-(neighbor)\n",
        "          RETURN neighbor.id + ' - ' + type(r) + ' -> ' + Superpopulation.Superpopulation_name AS output\n",
        "        }}\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        result += \"\\n\".join([str(el['output']) for el in response]) # changed this line to stringify the neighbor\n",
        "    return result"
      ],
      "metadata": {
        "id": "tEBbvarDOfsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_string_property_keys():\n",
        "    driver = GraphDatabase.driver(uri=os.environ[\"NEO4J_URI\"],auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"]))\n",
        "    with driver.session() as session:\n",
        "        result = session.run(\"\"\"\n",
        "            MATCH (n)\n",
        "            UNWIND keys(n) AS key\n",
        "            WITH DISTINCT key\n",
        "            RETURN key\n",
        "        \"\"\")\n",
        "        property_keys = []\n",
        "        for record in result:\n",
        "            key = record[\"key\"]\n",
        "            # Check if the property values are strings\n",
        "            prop_result = session.run(f\"\"\"\n",
        "                MATCH (n)\n",
        "                WHERE n.`{key}` IS NOT NULL\n",
        "                RETURN n.`{key}` AS value LIMIT 1\n",
        "            \"\"\")\n",
        "            value = prop_result.single()[\"value\"]\n",
        "            if isinstance(value, str):\n",
        "                property_keys.append(key)\n",
        "        return property_keys\n",
        "\n",
        "# Get string property keys\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def initialize_fulltext_index(entity):\n",
        "  label_properties = get_string_property_keys()\n",
        "  neo4j_graph_vector_index = Neo4jVector.from_existing_graph(\n",
        "      embedding=OpenAIEmbeddings(),\n",
        "      url=os.getenv(\"NEO4J_URI\"),\n",
        "      username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "      password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "      node_label=entity[0],\n",
        "      text_node_properties=label_properties ,\n",
        "      embedding_node_property=\"embedding\",\n",
        ")"
      ],
      "metadata": {
        "id": "C7r4hXxi8-AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "superpopulation_details_chat_template_str = \"\"\"\n",
        "Your job is to use the provided Race (superpopulation) data to answer\n",
        "questions about cancer types, sex and samples. Use the following context to answer questions.\n",
        "Be as detailed as possible, but don't make up any information that's\n",
        "not from the context and the entity_info. If you don't know an answer, say you don't know.\n",
        "{context}\n",
        "\"\"\"\n",
        "superpopulation_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=superpopulation_details_chat_template_str\n",
        "    )\n",
        ")\n",
        "human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"question\"],\n",
        "        template=\"Can you provide details on: {question}?\"\n",
        "    )\n",
        ")\n",
        "messages = [superpopulation_details_chat_system_prompt, human_prompt]\n",
        "qa_prompt = ChatPromptTemplate(\n",
        "    messages=messages,\n",
        "    input_variables=[\"context\", \"question\", \"entity_info\"]\n",
        ")\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=neo4j_graph_vector_index.as_retriever(),\n",
        "    # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
        "    chain_type=\"stuff\",\n",
        ")\n",
        "qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "B43Pbdr3-DBU",
        "outputId": "60c57a7b-5ef0-49b8-e59b-2fa06eb9045e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'neo4j_graph_vector_index' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a571251ba6d4>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m qa_chain = RetrievalQA.from_chain_type(\n\u001b[1;32m     28\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneo4j_graph_vector_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# ['stuff', 'map_reduce', 'refine', 'map_rerank']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stuff\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'neo4j_graph_vector_index' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def graphRAG_search(query):\n",
        "  neo4j_driver = GraphDatabase.driver(uri=os.environ[\"NEO4J_URI\"],auth=(\"neo4j\", os.environ[\"NEO4J_PASSWORD\"]))\n",
        "\n",
        "  query=query\n",
        "  superpopulation_details_chat_template_str = \"\"\"\n",
        "  Your job is to use the provided Race (superpopulation) data to answer\n",
        "  questions about cancer types, sex and samples. Use the following context to answer questions.\n",
        "  Be as detailed as possible, but don't make up any information that's\n",
        "  not from the context and the entity_info. If you don't know an answer, say you don't know.\n",
        "  {context}\n",
        "  \"\"\"\n",
        "  superpopulation_details_chat_system_prompt = SystemMessagePromptTemplate(\n",
        "      prompt=PromptTemplate(\n",
        "          input_variables=[\"context\"],\n",
        "          template=superpopulation_details_chat_template_str\n",
        "      )\n",
        "  )\n",
        "  human_prompt = HumanMessagePromptTemplate(\n",
        "      prompt=PromptTemplate(\n",
        "          input_variables=[\"question\"],\n",
        "          template=\"Can you provide details on: {question}?\"\n",
        "      )\n",
        "  )\n",
        "  messages = [superpopulation_details_chat_system_prompt, human_prompt]\n",
        "  qa_prompt = ChatPromptTemplate(\n",
        "      messages=messages,\n",
        "      input_variables=[\"context\", \"question\", \"entity_info\"]\n",
        "  )\n",
        "\n",
        "\n",
        "  label_properties = get_string_property_keys()\n",
        "\n",
        "\n",
        "  #query = \"What do you know about the Hispanic?\"\n",
        "  search_entity = entity_chain.invoke({\"question\": query}).names\n",
        "  search_label= get_entity_label_by_property(search_entity[0])\n",
        "  neo4j_graph_vector_index = Neo4jVector.from_existing_graph(\n",
        "        embedding=OpenAIEmbeddings(),\n",
        "        url=os.getenv(\"NEO4J_URI\"),\n",
        "        username=os.getenv(\"NEO4J_USERNAME\"),\n",
        "        password=os.getenv(\"NEO4J_PASSWORD\"),\n",
        "        node_label=search_label[0],\n",
        "        text_node_properties=label_properties ,\n",
        "        embedding_node_property=\"embedding\",\n",
        "  )\n",
        "\n",
        "  lm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "  qa_chain = RetrievalQA.from_chain_type(\n",
        "      llm=llm,\n",
        "      retriever=neo4j_graph_vector_index.as_retriever(),\n",
        "      # ['stuff', 'map_reduce', 'refine', 'map_rerank']\n",
        "      chain_type=\"stuff\",\n",
        "  )\n",
        "  qa_chain.combine_documents_chain.llm_chain.prompt = qa_prompt\n",
        "\n",
        "\n",
        "\n",
        "  initialize_fulltext_index(search_label)\n",
        "  entity_info=graph_retriever_Superpopulation(query)\n",
        "  #max_entity_info_length = 310\n",
        "  #entity_info = entity_info[:max_entity_info_length]\n",
        "  print(entity_info)\n",
        "\n",
        "  # Step 1: Retrieve context\n",
        "  retrieved_docs = qa_chain.retriever.get_relevant_documents(query)\n",
        "  context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
        "\n",
        "  # Step 2: Combine 'entity_info' into 'context'\n",
        "  full_context = f\"{context}\\n the entities and the relationships {entity_info}\"\n",
        "  # Step 3: Invoke the chain\n",
        "  response = qa_chain.combine_documents_chain.llm_chain.predict(\n",
        "      context=full_context,\n",
        "      question=query\n",
        "  )\n",
        "  print(response)\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "xL_PtFAu_TP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph entity extraction"
      ],
      "metadata": {
        "id": "nMS4n_dNCkMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***GRAPH_RAG***"
      ],
      "metadata": {
        "id": "2jocAE-o85hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global constants\n",
        "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
        "VECTOR_NODE_LABEL = 'Chunk'\n",
        "VECTOR_SOURCE_PROPERTY = 'text'\n",
        "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "NEO4J_DATABASE = 'neo4j'\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
        ")\n",
        "\n",
        "kg.refresh_schema()\n"
      ],
      "metadata": {
        "id": "a8YN-xK0BSrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "MATCH (c:Cancer_Type)-[:OCCUR_IN]->(n:county)\n",
        "RETURN c, n\n",
        "LIMIT 1\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNI2q0Q0CnoS",
        "outputId": "5841d3eb-13a2-459d-9525-9f193f1485d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'c': {'Cancer_Type': 'Breast'},\n",
              "  'n': {'County_FIPS': 48201, 'County': 'Harris'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to\n",
        "query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the\n",
        "schema. Do not use any other relationship types or properties that\n",
        "are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note:\n",
        "Do not respond to any questions that might ask anything else than\n",
        "for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Examples: Here are a few examples of generated Cypher\n",
        "statements for particular questions:\n",
        "\n",
        "# what is the most deadliest genotype in texas?\n",
        "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)-[hg:HAS_GENOTYPE]->(snp:SNP)\n",
        "WHERE st.State = 'Texas'\n",
        "RETURN hg.genotype, COUNT(hg) as sample_count, hg, s, c, snp\n",
        "ORDER BY sample_count DESC\n",
        "LIMIT 1\n",
        "\n",
        "\n",
        "#What do you know about the Hispanic?\n",
        "MATCH (sp:Superpopulation)-[r:!MENTIONS]->(n)\n",
        "WHERE sp.Superpopulation_name = 'Hispanic'\n",
        "RETURN sp.Superpopulation_name, r, n\n",
        "\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\""
      ],
      "metadata": {
        "id": "cpoORTD0DQTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_qa_prompt = \"\"\"You are an assistant that helps to form nice and human understandable answers.\n",
        "The information part contains the provided information that you must use to construct an answer.\n",
        "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
        "Make the answer sound as a response to the question. Use the question to formulate a full answer.\n",
        "If the provided information is empty, say that you don't know the answer.\n",
        "Final answer should be easily readable and structured.\n",
        "Information:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=CYPHER_GENERATION_TEMPLATE\n",
        ")\n",
        "\n",
        "qa_prompt = PromptTemplate(\n",
        "input_variables=[\"context\", \"question\"], template=cypher_qa_prompt)\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"], temperature=0.0)\n",
        "\n",
        "cypherChain = GraphCypherQAChain.from_llm(\n",
        "    top_k=100,\n",
        "    llm=llm,\n",
        "    graph=kg,\n",
        "    verbose=True,\n",
        "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
        "    allow_dangerous_requests=True,\n",
        "    qa_prompt=qa_prompt\n",
        ")\n",
        "def prettyCypherChain(question: str) -> str:\n",
        "    #g=graphRAG_search(question)\n",
        "    #context = f\"{cypherChain.graph_schema}, {g}\"\n",
        "    #response = cypherChain.run(question)\n",
        "\n",
        "    response1 = cypherChain.run(question)\n",
        "    return response1\n",
        "    print(textwrap.fill(response1, 60))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "juE_urY4Gais"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettyCypherChain(\"what is the most deadliest genotype in texas?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "GtK8iVmcGtyw",
        "outputId": "1563ecb5-840b-4fd9-e690-170580f2ec5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)-[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "RETURN hg.genotype, COUNT(hg) as sample_count, hg, s, c, snp\n",
            "ORDER BY sample_count DESC\n",
            "LIMIT 1\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'hg.genotype': '0|0', 'sample_count': 1, 'hg': ({'Sample_name': 'NA21134'}, 'HAS_GENOTYPE', {'allele_number': 5096, 'allele_count': 231, 'depth': 9775, 'Gene': '-', 'alt_allele': 'T', 'id': 'rs1454849680', 'position': 16038675, 'overall_af': 0.05, 'Gene_symbol': '-', 'num_samples': 2548, 'ref_allele': 'C'}), 's': {'Sample_name': 'NA21134'}, 'c': {'County_FIPS': 48201, 'id': 'Harris'}, 'snp': {'allele_number': 5096, 'allele_count': 231, 'depth': 9775, 'Gene': '-', 'alt_allele': 'T', 'id': 'rs1454849680', 'position': 16038675, 'overall_af': 0.05, 'Gene_symbol': '-', 'num_samples': 2548, 'ref_allele': 'C'}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The sample named NA21134 has a genotype of 0|0. This sample was tested for the SNP with the ID rs1454849680. The SNP is located at position 16038675 and has a reference allele of 'C' and an alternate allele of 'T'. The overall allele frequency is 0.05. The total number of samples tested for this SNP is 2548, and the allele count is 231 out of an allele number of 5096. The depth of the sequencing data is 9775. The gene associated with this SNP is not specified. The sample comes from Harris county with the FIPS code 48201.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Respon 2"
      ],
      "metadata": {
        "id": "Gza6Og99lXXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CYPHER_GENERATION_TEMPLATE2 = \"\"\"Task:Generate Cypher statement to\n",
        "query a graph database.\n",
        "Instructions:\n",
        "Use only the provided relationship types and properties in the\n",
        "schema. Do not use any other relationship types or properties that\n",
        "are not provided.\n",
        "Schema:\n",
        "{schema}\n",
        "Note:\n",
        "Do not respond to any questions that might ask anything else than\n",
        "for you to construct a Cypher statement.\n",
        "Do not include any text except the generated Cypher statement.\n",
        "Examples: Here are a few examples of generated Cypher\n",
        "statements for particular questions:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# what is the most deadliest genotype in texas?\n",
        "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
        "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
        "WHERE st.State = 'Texas'\n",
        "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\n",
        "\n",
        "ORDER BY genotype_count DESC\n",
        "LIMIT 1\n",
        "RETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\n",
        "\n",
        "UNION ALL\n",
        "\n",
        "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
        "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
        "WHERE st.State = 'Texas'\n",
        "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\n",
        "\n",
        "ORDER BY genotype_count DESC\n",
        "LIMIT 1\n",
        "MATCH (s:sample)-[r:!MENTIONS]->(neighbor)\n",
        "WHERE s.Sample_name = Sample_name1\n",
        "RETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\n",
        "\n",
        "\n",
        "UNION ALL\n",
        "\n",
        "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
        "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
        "WHERE st.State = 'Texas'\n",
        "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\n",
        "\n",
        "ORDER BY genotype_count DESC\n",
        "LIMIT 1\n",
        "MATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\n",
        "WHERE s.Sample_name = Sample_name1\n",
        "RETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#What do you know about the Hispanic?\n",
        "MATCH (sp:Superpopulation)-[r:!MENTIONS]->(n)\n",
        "WHERE sp.Superpopulation_name = 'Hispanic'\n",
        "RETURN sp.Superpopulation_name, r, n\n",
        "\n",
        "\n",
        "The question is:\n",
        "{question}\"\"\""
      ],
      "metadata": {
        "id": "AvFdqq4BmDb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_qa_prompt2 = \"\"\"You are an assistant that helps to form nice and human understandable answers.\n",
        "The information part contains the provided information that you must use to construct an answer.\n",
        "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
        "Make the answer sound as a response to the question. Use the question to formulate a full answer.\n",
        "If the provided information is empty, say that you don't know the answer.\n",
        "Final answer should be easily readable and structured.\n",
        "Information:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"schema\", \"question\"],\n",
        "    template=CYPHER_GENERATION_TEMPLATE2\n",
        ")\n",
        "\n",
        "qa_prompt = PromptTemplate(\n",
        "input_variables=[\"context\", \"question\"], template=cypher_qa_prompt2)\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"], temperature=0.0)\n",
        "\n",
        "cypherChain2 = GraphCypherQAChain.from_llm(\n",
        "    top_k=100,\n",
        "    llm=llm,\n",
        "    graph=kg,\n",
        "    verbose=True,\n",
        "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
        "    allow_dangerous_requests=True,\n",
        "    qa_prompt=qa_prompt\n",
        ")\n",
        "def prettyCypherChain2(question: str) -> str:\n",
        "    #g=graphRAG_search(question)\n",
        "    #context = f\"{cypherChain.graph_schema}, {g}\"\n",
        "    #response = cypherChain.run(question)\n",
        "\n",
        "    response2 = cypherChain2.run(question)\n",
        "    return response2\n",
        "    print(textwrap.fill(response1, 60))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f2W1YF8Al0f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettyCypherChain2(\"what is the most deadliest genotype in texas?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RXcWtQ3zlxv_",
        "outputId": "31e298e7-8f29-403c-b137-8dec3b87a717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
            "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\n",
            "     \n",
            "ORDER BY genotype_count DESC\n",
            "LIMIT 1 \n",
            "RETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\n",
            "\n",
            "UNION ALL\n",
            "\n",
            "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
            "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\n",
            "     \n",
            "ORDER BY genotype_count DESC\n",
            "LIMIT 1 \n",
            "MATCH (s:sample)-[r:!MENTIONS]->(neighbor)\n",
            "WHERE s.Sample_name = Sample_name1\n",
            "RETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\n",
            "\n",
            "\n",
            "UNION ALL\n",
            "\n",
            "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
            "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\n",
            "     \n",
            "ORDER BY genotype_count DESC\n",
            "LIMIT 1 \n",
            "MATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\n",
            "WHERE s.Sample_name = Sample_name1\n",
            "RETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: MENTIONS)} {position: line: 19, column: 22, offset: 665} for query: \"MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nRETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)-[r:!MENTIONS]->(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\\n\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: MENTIONS)} {position: line: 33, column: 23, offset: 1091} for query: \"MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nRETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)-[r:!MENTIONS]->(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\\n\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'output': 'NA21134 with genotype 0|0 231 sample_count '}, {'output': None}, {'output': None}, {'output': None}, {'output': 'NA21134 - COLLECT_FROM -> Harris'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1454849680'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1160632320'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1473857766'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1228971855'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1176286927'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1427290039'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1247236590'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1302756061'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1381118581'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1236756715'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1345872846'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1332670268'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1293182703'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1351481019'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs936990738'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs916816458'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2139620105'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1271109451'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089204274'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1004947043'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1168556733'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1028948669'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs949576520'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1311846483'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089204865'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs890392704'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1418238236'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1000434954'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1175722323'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1201458425'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs940876481'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1314848291'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1050465694'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs944691826'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs894243612'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1345024770'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1367181594'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2139620330'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs973616940'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs920734544'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs911976120'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs944745721'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2139620363'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs924532256'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs935890754'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs894326071'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1045545862'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1015246115'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs986256488'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs911987237'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs966059368'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1200736942'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs936000753'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1346706359'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1276917611'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs915827838'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs948593697'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1240659911'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1213365466'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1007686014'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1458033728'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089208175'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs981287467'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1313717002'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1303917012'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs902041280'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs970034366'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs939871851'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089209667'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs889486847'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs943686621'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs998985999'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1031799111'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs893227186'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1035617757'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1226427121'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs961246113'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs919739326'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs985248449'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs943740520'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs994125366'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1027296935'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs952612962'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089211269'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs976405146'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1215007198'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs905967590'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1002931483'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs965111760'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1180461063'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1319955253'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs956433067'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1424688658'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs927475878'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1394830486'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The sample NA21134 has a genotype of 0|0 with a sample count of 231. It was collected from Harris. The sample NA21134 has the following genotypes: rs1454849680, rs1160632320, rs1473857766, rs1228971855, rs1176286927, rs1427290039, rs1247236590, rs1302756061, rs1381118581, rs1236756715, rs1345872846, rs1332670268, rs1293182703, rs1351481019, rs936990738, rs916816458, rs2139620105, rs1271109451, rs2089204274, rs1004947043, rs1168556733, rs1028948669, rs949576520, rs1311846483, rs2089204865, rs890392704, rs1418238236, rs1000434954, rs1175722323, rs1201458425, rs940876481, rs1314848291, rs1050465694, rs944691826, rs894243612, rs1345024770, rs1367181594, rs2139620330, rs973616940, rs920734544, rs911976120, rs944745721, rs2139620363, rs924532256, rs935890754, rs894326071, rs1045545862, rs1015246115, rs986256488, rs911987237, rs966059368, rs1200736942, rs936000753, rs1346706359, rs1276917611, rs915827838, rs948593697, rs1240659911, rs1213365466, rs1007686014, rs1458033728, rs2089208175, rs981287467, rs1313717002, rs1303917012, rs902041280, rs970034366, rs939871851, rs2089209667, rs889486847, rs943686621, rs998985999, rs1031799111, rs893227186, rs1035617757, rs1226427121, rs961246113, rs919739326, rs985248449, rs943740520, rs994125366, rs1027296935, rs952612962, rs2089211269, rs976405146, rs1215007198, rs905967590, rs1002931483, rs965111760, rs1180461063, rs1319955253, rs956433067, rs1424688658, rs927475878, rs1394830486.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Final integration***"
      ],
      "metadata": {
        "id": "dWFkW0WJlvKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Define the prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are an assistant that combines two pieces of information into a singal answer.\n",
        "The information part contains the provided information that you must use to construct an answer.\n",
        "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
        "Make the answer sound as a response to the question. Use the question to formulate a full answer.\n",
        "If the provided information is empty, say that you don't know the answer.\n",
        "Final answer should be easily readable and structured.\n",
        "\n",
        "Information 1:\n",
        "{output1}\n",
        "\n",
        "Information 2:\n",
        "{output2}\n",
        "\n",
        "Please provide a combined summary of the above information.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"output1\", \"output2\"],\n",
        "    template=prompt_template\n",
        ")\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Create an LLMChain with the prompt and model\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Define the outputs you want to combine\n",
        "output1 = prettyCypherChain(\"what is the most deadliest genotype in texas?\")\n",
        "output2 = prettyCypherChain2(\"what is the most deadliest genotype in texas?\")\n",
        "\n",
        "# Run the chain with the inputs\n",
        "combined_summary = chain.run(output1=output1, output2=output2)\n",
        "\n",
        "# Print the result\n",
        "print(textwrap.fill(combined_summary, 60))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-6TlY2gkRLa",
        "outputId": "ce91c957-bb90-4c51-d3ef-1b734fa0568a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)-[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "RETURN hg.genotype, COUNT(hg) as sample_count, hg, s, c, snp\n",
            "ORDER BY sample_count DESC\n",
            "LIMIT 1\u001b[0m\n",
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'hg.genotype': '0|0', 'sample_count': 1, 'hg': ({'Sample_name': 'NA21134'}, 'HAS_GENOTYPE', {'allele_number': 5096, 'allele_count': 231, 'depth': 9775, 'Gene': '-', 'alt_allele': 'T', 'id': 'rs1454849680', 'position': 16038675, 'overall_af': 0.05, 'Gene_symbol': '-', 'num_samples': 2548, 'ref_allele': 'C'}), 's': {'Sample_name': 'NA21134'}, 'c': {'County_FIPS': 48201, 'id': 'Harris'}, 'snp': {'allele_number': 5096, 'allele_count': 231, 'depth': 9775, 'Gene': '-', 'alt_allele': 'T', 'id': 'rs1454849680', 'position': 16038675, 'overall_af': 0.05, 'Gene_symbol': '-', 'num_samples': 2548, 'ref_allele': 'C'}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
            "Generated Cypher:\n",
            "\u001b[32;1m\u001b[1;3mMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
            "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\n",
            "     \n",
            "ORDER BY genotype_count DESC\n",
            "LIMIT 1 \n",
            "RETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\n",
            "\n",
            "UNION ALL\n",
            "\n",
            "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
            "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\n",
            "     \n",
            "ORDER BY genotype_count DESC\n",
            "LIMIT 1 \n",
            "MATCH (s:sample)-[r:!MENTIONS]->(neighbor)\n",
            "WHERE s.Sample_name = Sample_name1\n",
            "RETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\n",
            "\n",
            "\n",
            "UNION ALL\n",
            "\n",
            "MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\n",
            "      -[hg:HAS_GENOTYPE]->(snp:SNP)\n",
            "WHERE st.State = 'Texas'\n",
            "WITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\n",
            "     \n",
            "ORDER BY genotype_count DESC\n",
            "LIMIT 1 \n",
            "MATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\n",
            "WHERE s.Sample_name = Sample_name1\n",
            "RETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: MENTIONS)} {position: line: 19, column: 22, offset: 665} for query: \"MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nRETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)-[r:!MENTIONS]->(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\\n\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownRelationshipTypeWarning} {category: UNRECOGNIZED} {title: The provided relationship type is not in the database.} {description: One of the relationship types in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing relationship type is: MENTIONS)} {position: line: 33, column: 23, offset: 1091} for query: \"MATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nRETURN Sample_name +' '+ 'with genotype' +' '+ genotype + ' ' + genotype_count + ' sample_count 'AS output\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)-[r:!MENTIONS]->(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN s.Sample_name + ' - ' + type(r)+ ' -> ' + neighbor.id AS output\\n\\n\\nUNION ALL\\n\\nMATCH (st:state)-[:HAS_COUNTY]->(c:county)<-[:COLLECT_FROM]-(s:sample)\\n      -[hg:HAS_GENOTYPE]->(snp:SNP)\\nWHERE st.State = 'Texas'\\nWITH hg.genotype AS genotype, COUNT(*) AS genotype_count,s.Sample_name AS Sample_name1\\n     \\nORDER BY genotype_count DESC\\nLIMIT 1 \\nMATCH (s:sample)<-[r:!MENTIONS]-(neighbor)\\nWHERE s.Sample_name = Sample_name1\\nRETURN neighbor.id+ ' - ' + type(r)+ ' -> ' + s.Sample_name AS output\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Context:\n",
            "\u001b[32;1m\u001b[1;3m[{'output': 'NA21134 with genotype 0|0 231 sample_count '}, {'output': None}, {'output': None}, {'output': None}, {'output': 'NA21134 - COLLECT_FROM -> Harris'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1454849680'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1160632320'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1473857766'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1228971855'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1176286927'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1427290039'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1247236590'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1302756061'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1381118581'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1236756715'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1345872846'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1332670268'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1293182703'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1351481019'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs936990738'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs916816458'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2139620105'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1271109451'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089204274'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1004947043'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1168556733'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1028948669'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs949576520'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1311846483'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089204865'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs890392704'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1418238236'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1000434954'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1175722323'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1201458425'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs940876481'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1314848291'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1050465694'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs944691826'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs894243612'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1345024770'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1367181594'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2139620330'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs973616940'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs920734544'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs911976120'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs944745721'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2139620363'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs924532256'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs935890754'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs894326071'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1045545862'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1015246115'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs986256488'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs911987237'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs966059368'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1200736942'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs936000753'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1346706359'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1276917611'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs915827838'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs948593697'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1240659911'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1213365466'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1007686014'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1458033728'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089208175'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs981287467'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1313717002'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1303917012'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs902041280'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs970034366'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs939871851'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089209667'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs889486847'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs943686621'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs998985999'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1031799111'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs893227186'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1035617757'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1226427121'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs961246113'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs919739326'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs985248449'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs943740520'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs994125366'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1027296935'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs952612962'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs2089211269'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs976405146'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1215007198'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs905967590'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1002931483'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs965111760'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1180461063'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1319955253'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs956433067'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1424688658'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs927475878'}, {'output': 'NA21134 - HAS_GENOTYPE -> rs1394830486'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The sample named NA21134, which was collected from Harris\n",
            "county (FIPS code 48201), has a genotype of 0|0 for the SNP\n",
            "with the ID rs1454849680. This SNP is located at position\n",
            "16038675, with a reference allele of 'C' and an alternate\n",
            "allele of 'T'. The overall allele frequency of this SNP is\n",
            "0.05. The sample was part of a test involving 2548 samples,\n",
            "with an allele count of 231 out of a total allele number of\n",
            "5096. The depth of the sequencing data is 9775.\n",
            "Additionally, the sample NA21134 has genotypes for a wide\n",
            "array of rsIDs, including but not limited to rs1160632320,\n",
            "rs1473857766, and rs1228971855. The sample count for NA21134\n",
            "is 231. The gene associated with the SNP rs1454849680 is not\n",
            "specified.\n"
          ]
        }
      ]
    }
  ]
}